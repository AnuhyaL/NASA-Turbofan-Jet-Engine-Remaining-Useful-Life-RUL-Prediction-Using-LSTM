# NASA-Turbofan-Jet-Engine-Remaining-Useful-Life-RUL-Prediction-Using-LSTM

**Students Information**

Name: Anuhya Lanke, Drashti Sheta

Email: alanke@stevens.edu, dsheta@stevens.edu

# Project Overview

Predictive maintenance is a critical component of modern aerospace systems, enabling early fault detection, reduced downtime, and optimized maintenance costs. One of the most important predictive maintenance tasks is Remaining Useful Life (RUL) estimation, which predicts how many operational cycles remain before an engine failure occurs.

This project presents an end-to-end machine learning and deep learning solution for predicting the RUL of turbofan jet engines using the NASA C-MAPSS dataset. Both a traditional machine learning model (Random Forest Regressor) and a deep learning model (Long Short-Term Memory â€“ LSTM) were implemented and evaluated. Based on performance comparison, the LSTM model was selected as the final solution due to its superior ability to capture temporal degradation patterns.

## â–¶ Run the Application (No Download Required)

The Streamlit web application is deployed and can be accessed directly using the link below:

ðŸ”— [https://nasa-turbofan-jet-engine.streamlit.app/]

No local installation or code download is required to run the project.


# Problem Description

The NASA C-MAPSS dataset contains multivariate time-series sensor readings collected from multiple turbofan engines operating under varying conditions. Each engine degrades over time until failure, but the degradation patterns are complex and non-linear.
**
Objective:** To predict the Remaining Useful Life (RUL) of an engine at any given operational cycle using historical sensor data.

# Key Challenges:

â€¢ Modeling long-term temporal dependencies

â€¢ Handling multivariate sensor data

â€¢ Learning degradation trends without explicit failure indicators

â€¢ Improving prediction accuracy over traditional ML methods

# Project Structure

NASA-RUL-LSTM/

â”œâ”€â”€ app.py # Streamlit web application

â”œâ”€â”€ data_processing.py # Data loading, RUL computation, preprocessing

â”œâ”€â”€ models.py # LSTM model definition and training logic

â”œâ”€â”€ utils.py # Evaluation metrics and visualization

â”œâ”€â”€ README.md # Project documentation

All necessary files are included to run, evaluate, and interact with the project.

# Workflow & Methodology

# Data Loading

The project uses the NASA C-MAPSS datasets (FD001â€“FD004).

Each dataset contains:

â€¢ Engine unit ID

â€¢ Cycle number

â€¢ 3 operational settings

â€¢ 21 sensor measurements

Users can either:

â€¢ Use the default dataset, or

â€¢ Upload their own dataset through the Streamlit interface

# Remaining Useful Life (RUL) Calculation

**For each engine:**

â€¢ RUL is computed as the difference between the final failure cycle and the current cycle

â€¢ An optional RUL cap is applied to reduce extreme values and stabilize training

# Data Preprocessing & Feature Engineering

â€¢ Sensor and operational features are normalized using standard scaling

â€¢ Sliding-window sequences are created to transform time-series data into fixed-length sequences

â€¢ These sequences are used as inputs for the LSTM model

# Model Development

# Random Forest Regressor (Baseline Model)

A Random Forest regression model was implemented as a baseline to evaluate traditional machine learning performance. 

**Approach:**

â€¢ Extracted statistical features (mean, standard deviation) from sensor windows

â€¢ Used these handcrafted features for regression

**Observed Performance:**

â€¢ RMSE: ~35â€“40 cycles

â€¢ RÂ² Score: ~0.20â€“0.30


**Limitations:**

â€¢ Does not explicitly model temporal dependencies

â€¢ Relies on handcrafted features

â€¢ Struggles with long-term degradation trends

â€¢ Significantly lower accuracy compared to sequence-based models

â€¢ Due to these limitations, Random Forest was not selected as the final model.

# LSTM Model (Final Model)

A multi-layer Long Short-Term Memory (LSTM) network was implemented to directly model sequential sensor behavior across engine cycles.

Since the C-MAPSS datasets differ in operating conditions and sensor behavior, model hyperparameters and data preprocessing settings such as sequence length, RUL cap, and normalization parameters were adjusted accordingly to ensure stable training and optimal performance.

Why LSTM?

â€¢ Captures long-term temporal dependencies

â€¢ Learns degradation patterns automatically

â€¢ Handles multivariate time-series data effectively

â€¢ Provides significantly improved prediction accuracy

# Model Training & Evaluation

**Training Configuration:**

â€¢ Loss Function: Mean Squared Error (MSE)

â€¢ Optimizer: Adam

**Tunable hyperparameters:**

â€¢ Sequence length

â€¢ Batch size

â€¢ Number of hidden units

â€¢ Number of epochs

**Evaluation Metrics:**

â€¢ RMSE (Root Mean Squared Error)

â€¢ RÂ² Score (Coefficient of Determination)

# Results Summary

**Models**

Random Forest -RMSE (cycles) = ~35-40, RÂ² Score = ~0.20-0.30

LSTM(Final)- RMSE (cycles) = 8.68, RÂ² Score = 0.959

The LSTM model shows a substantial improvement over the baseline, confirming the importance of temporal modeling for RUL prediction.

# Streamlit Web Application

â€¢ An interactive Streamlit-based interface is included, allowing users to:

â€¢ Upload C-MAPSS datasets

â€¢ Configure RUL cap and sequence length

â€¢ Tune LSTM hyperparameters

â€¢ Train models interactively

â€¢ View evaluation metrics and prediction plots

# How to Run the Project

â€¢ git clone

â€¢ cd NASA-RUL-LSTM

â€¢ pip install -r requirements.txt

â€¢ streamlit run app.py

**(The dataset is in the .zip file so need to exact it before uploading it in the code)**

# RECOMMENDED SETTINGS FOR EACH DATASET

ðŸ”¹ FD001 (Baseline / Simple case)

Files used

train_FD001.txt

test_FD001.txt

RUL_FD001.txt

Parameter,	Value

RUL Cap	- 125

Sequence Length	- 30â€“40

Epochs	- 10â€“15

Batch Size	- 64

Hidden Size	- 64

LSTM Layers	- 1â€“2

ðŸ”¹ FD002 (Multiple operating conditions)

Files used

train_FD002.txt

test_FD002.txt

RUL_FD002.txt

Parameter,	Value

RUL Cap	- 130â€“150

Sequence Length	- 40â€“50

Epochs	- 15â€“20

Batch Size	- 64

Hidden Size	- 64â€“128

LSTM Layers	- 2

ðŸ”¹ FD003  (MAIN DATASET â€“ RECOMMENDED)

Files used

train_FD003.txt

test_FD003.txt

RUL_FD003.txt

Parameter, Value, Reason

RUL Cap - 125 - Standard in literature

Sequence Length	- 50 -	Captures degradation trend

Epochs	- 20â€“30 -	Harder faults

Batch Size	- 64	- Stable

Hidden Size	- 64 or 128	- Enough capacity

LSTM Layers	- 2	- Avoid overfitting

ðŸ”¹ FD004 (Most difficult)

Files used

train_FD004.txt

test_FD004.txt

RUL_FD004.txt

Parameter,	Value

RUL Cap -	150

Sequence Length	- 60

Epochs	- 30

Batch Size	- 32â€“64

Hidden Size	- 128

LSTM Layers	- 2â€“3

# Contributions

Anuhya Lanke

1 - Added data loading & RUL calculation

2	- Implemented LSTM model

3	- Added Streamlit UI

4	- Added Exploratory Data Analysis

5	- Updated README and results

Drashti Sheta

1 - Improved Random Forest baseline

2 - Added model evaluation metrics

3 - Created prediction plots

4 - Final cleanup and testing

# Advanced Python & ML Features Used

â€¢ Object-Oriented Programming (custom model classes)

â€¢ Sliding-window sequence generation

â€¢ Exception handling using tryâ€“except

â€¢ Generator-style batch processing

**Libraries:**

â€¢ PyTorch

â€¢ Streamlit

â€¢ scikit-learn

â€¢ pandas

â€¢ NumPy

# Dataset

â€¢ NASA C-MAPSS Turbofan Engine Degradation Dataset

â€¢ Public benchmark dataset from NASA Prognostics Center of Excellence

# Results

The proposed LSTM model was evaluated on the NASA CMAPSS FD003 dataset using RMSE and RÂ² metrics. The model achieved an RMSE of approximately 8â€“15 cycles and an RÂ² score between 0.90 and 0.96, indicating strong predictive accuracy. The Predicted vs. True RUL plots show close alignment with the ideal diagonal, confirming effective learning of degradation trends. Compared to a Random Forest baseline (RMSE â‰ˆ 35â€“40, RÂ² â‰ˆ 0.20â€“0.30), the LSTM model significantly outperforms by capturing temporal dependencies in sensor data.

# Conclusion

This project demonstrates a complete end-to-end predictive maintenance pipeline for turbofan engine Remaining Useful Life prediction. By comparing a traditional Random Forest baseline with a deep learning LSTM model, the study highlights the critical importance of temporal modeling in degradation analysis. The LSTM-based approach significantly outperforms the baseline, achieving high accuracy and robustness, making it suitable for real-world aerospace maintenance applications.

