# NASA-Turbofan-Jet-Engine-Remaining-Useful-Life-RUL-Prediction-Using-LSTM

**Students Information**

Name: Anuhya Lanke, Drashti Sheta

Email: alanke@stevens.edu, dsheta@stevens.edu

# Project Overview

Predictive maintenance is a critical component of modern aerospace systems, enabling early fault detection, reduced downtime, and optimized maintenance costs. One of the most important predictive maintenance tasks is Remaining Useful Life (RUL) estimation, which predicts how many operational cycles remain before an engine failure occurs.

This project presents an end-to-end machine learning and deep learning solution for predicting the RUL of turbofan jet engines using the NASA C-MAPSS dataset. Both a traditional machine learning model (Random Forest Regressor) and a deep learning model (Long Short-Term Memory â€“ LSTM) were implemented and evaluated. Based on performance comparison, the LSTM model was selected as the final solution due to its superior ability to capture temporal degradation patterns.

## â–¶ Run the Application (No Download Required)

The Streamlit web application is deployed and can be accessed directly using the link below:

ðŸ”— [https://nasa-turbofan-jet-engine.streamlit.app/]

No local installation or code download is required to run the project but dataset download is required.

**Instruction to download manually are given below as How to run the code** 


# Problem Description

The NASA C-MAPSS dataset contains multivariate time-series sensor readings collected from multiple turbofan engines operating under varying conditions. Each engine degrades over time until failure, but the degradation patterns are complex and non-linear.
**
Objective:** To predict the Remaining Useful Life (RUL) of an engine at any given operational cycle using historical sensor data.

# Key Challenges:

â€¢ Modeling long-term temporal dependencies

â€¢ Handling multivariate sensor data

â€¢ Learning degradation trends without explicit failure indicators

â€¢ Improving prediction accuracy over traditional ML methods

# Project Structure

NASA-RUL-LSTM/

â”œâ”€â”€ app.py # Streamlit web application

â”œâ”€â”€ data_processing.py # Data loading, RUL computation, preprocessing

â”œâ”€â”€ models.py # LSTM model definition and training logic

â”œâ”€â”€ utils.py # Evaluation metrics and visualization

â”œâ”€â”€ README.md # Project documentation

All necessary files are included to run, evaluate, and interact with the project.

# Workflow & Methodology

# Data Loading

The project uses the NASA C-MAPSS datasets (FD001â€“FD004).

Each dataset contains:

â€¢ Engine unit ID

â€¢ Cycle number

â€¢ 3 operational settings

â€¢ 21 sensor measurements

Users can either:

â€¢ Use the default dataset, or

â€¢ Upload their own dataset through the Streamlit interface

# Remaining Useful Life (RUL) Calculation

**For each engine:**

â€¢ RUL is computed as the difference between the final failure cycle and the current cycle

â€¢ An optional RUL cap is applied to reduce extreme values and stabilize training

# Data Preprocessing & Feature Engineering

â€¢ Sensor and operational features are normalized using standard scaling

â€¢ Sliding-window sequences are created to transform time-series data into fixed-length sequences

â€¢ These sequences are used as inputs for the LSTM model

# Model Development

# Random Forest Regressor (Baseline Model)

A Random Forest regression model was implemented as a baseline to evaluate traditional machine learning performance. 

**Approach:**

â€¢ Extracted statistical features (mean, standard deviation) from sensor windows

â€¢ Used these handcrafted features for regression

**Observed Performance:**

â€¢ RMSE: ~35â€“40 cycles

â€¢ RÂ² Score: ~0.20â€“0.30


**Limitations:**

â€¢ Does not explicitly model temporal dependencies

â€¢ Relies on handcrafted features

â€¢ Struggles with long-term degradation trends

â€¢ Significantly lower accuracy compared to sequence-based models

â€¢ Due to these limitations, Random Forest was not selected as the final model.

# LSTM Model (Final Model)

A multi-layer Long Short-Term Memory (LSTM) network was implemented to directly model sequential sensor behavior across engine cycles.

Since the C-MAPSS datasets differ in operating conditions and sensor behavior, model hyperparameters and data preprocessing settings such as sequence length, RUL cap, and normalization parameters were adjusted accordingly to ensure stable training and optimal performance.

Why LSTM?

â€¢ Captures long-term temporal dependencies

â€¢ Learns degradation patterns automatically

â€¢ Handles multivariate time-series data effectively

â€¢ Provides significantly improved prediction accuracy

# Model Training & Evaluation

**Training Configuration:**

â€¢ Loss Function: Mean Squared Error (MSE)

â€¢ Optimizer: Adam

**Tunable hyperparameters:**

â€¢ Sequence length

â€¢ Batch size

â€¢ Number of hidden units

â€¢ Number of epochs

**Evaluation Metrics:**

â€¢ RMSE (Root Mean Squared Error)

â€¢ RÂ² Score (Coefficient of Determination)

# Results Summary

**Models**

Random Forest -RMSE (cycles) = ~35-40, RÂ² Score = ~0.20-0.30

LSTM(Final)- RMSE (cycles) = 8.68, RÂ² Score = 0.959

The LSTM model shows a substantial improvement over the baseline, confirming the importance of temporal modeling for RUL prediction.

# Streamlit Web Application

â€¢ An interactive Streamlit-based interface is included, allowing users to:

â€¢ Upload C-MAPSS datasets

â€¢ Configure RUL cap and sequence length

â€¢ Tune LSTM hyperparameters

â€¢ Train models interactively

â€¢ View evaluation metrics and prediction plots

# How to run the code

**Instructions for Downloading, Running, and Verifying the Project** 

* Download the project by clicking Code â†’ Download ZIP from the GitHub repository and extract it locally, or clone it using git clone.

* Ensure Python 3.12 or 3.13 is installed on the system before running the project.

* Install all required dependencies using pip install -r requirements.txt or manually install NumPy, Pandas, Matplotlib, Scikit-learn, PyTorch, Streamlit, and Pytest.

* Verify the project directory structure includes all required files: NASA_RUL_Main.ipynb, app.py, data_processing.py, models.py, utils.py, and the data/ and tests/ folders.

* Open the main Jupyter Notebook (NASA_RUL_Main.ipynb) and run all cells sequentially to execute the complete end-to-end workflow.

* Confirm that the notebook performs data loading, RUL computation, sliding-window sequence creation, LSTM training, and evaluation.

* Launch the interactive web interface using streamlit run app.py to visualize predictions and metrics.

* Run unit tests from the project root using python -m pytest to verify data loading and model functionality.

* Check the generated evaluation results in the results/metrics.txt file and observe prediction plots produced during execution.
  
* Or
  
*  after downloading the code exact it into a folder and open command prompt in it and type streamlit run app.py
  
* it will open streamlit GUI in the default browser then browse the file (dataset in train_FD001-FD004)
  
* then adjust the setting in the data according to the choice of dataset (recommendations given below) and click on the explanatory analysis and also click on the train the model
  
* It takes few minutes of time and give the plots

* when you do it manually you see the MSE for each epochs in the command prompt

**(The dataset is in the .zip file so need to exact it before uploading it in the code if downloading the code and doing manually)**

**The test datasets (FD001â€“FD004) do not contain per-cycle RUL labels. Therefore, RMSE and RÂ² metrics are reported only on training/validation data. For test datasets, the model generates RUL predictions that can be compared against the provided RUL text files when available.**

**Required to test the dataset on only train_FD001-FD004 in the data**

**Note: The dataset is provided in .zip format as Dataset.zip and folder as data in the Github for direct access**

# Unit Testing (PyTest)

* This project uses PyTest to validate data processing and model functionality before full execution.

* The file test_data.py verifies the dataset loading and preprocessing pipeline.

* It tests successful loading of the NASA CMAPSS dataset using load_cmapss.

* It confirms correct computation of the Remaining Useful Life (RUL) using add_rul.

* It ensures required columns and dataset structure are handled properly.

* The file test_model.py validates the LSTM-based RUL prediction model.

* It tests model initialization, training execution, and prediction output shape.

* It also verifies the __str__ method for proper model description.

* All tests are executed from the project root using python -m pytest.

* Successful test execution confirms correctness of data handling and model behavior.
  

# RECOMMENDED SETTINGS FOR EACH DATASET

ðŸ”¹ FD001 (Baseline / Simple case)

Files used

train_FD001.txt

test_FD001.txt

RUL_FD001.txt

Parameter,	Value

RUL Cap	- 125

Sequence Length	- 30â€“40

Epochs	- 10â€“15

Batch Size	- 64

Hidden Size	- 64

LSTM Layers	- 1â€“2

ðŸ”¹ FD002 (Multiple operating conditions)

Files used

train_FD002.txt

test_FD002.txt

RUL_FD002.txt

Parameter,	Value

RUL Cap	- 130â€“150

Sequence Length	- 40â€“50

Epochs	- 15â€“20

Batch Size	- 64

Hidden Size	- 64â€“128

LSTM Layers	- 2

ðŸ”¹ FD003  (MAIN DATASET â€“ RECOMMENDED)

Files used

train_FD003.txt

test_FD003.txt

RUL_FD003.txt

Parameter, Value, Reason

RUL Cap - 125 - Standard in literature

Sequence Length	- 50 -	Captures degradation trend

Epochs	- 20â€“30 -	Harder faults

Batch Size	- 64	- Stable

Hidden Size	- 64 or 128	- Enough capacity

LSTM Layers	- 2	- Avoid overfitting

ðŸ”¹ FD004 (Most difficult)

Files used

train_FD004.txt

test_FD004.txt

RUL_FD004.txt

Parameter,	Value

RUL Cap -	150

Sequence Length	- 60

Epochs	- 30

Batch Size	- 32â€“64

Hidden Size	- 128

LSTM Layers	- 2â€“3

# Contributions

Anuhya Lanke

1 - Added data loading & RUL calculation

2	- Implemented LSTM model

3	- Added Streamlit UI

4	- Added Exploratory Data Analysis

5	- Updated README and results

Drashti Sheta

1 - Improved Random Forest baseline

2 - Added model evaluation metrics

3 - Created prediction plots

4 - Final cleanup and testing

# Advanced Python & ML Features Used

â€¢ Object-Oriented Programming (custom model classes)

â€¢ Sliding-window sequence generation

â€¢ Exception handling using tryâ€“except

â€¢ Generator-style batch processing

**Libraries:**

â€¢ PyTorch

â€¢ Streamlit

â€¢ scikit-learn

â€¢ pandas

â€¢ NumPy

# Dataset

â€¢ NASA C-MAPSS Turbofan Engine Degradation Dataset



# Conclusion

This project demonstrates a complete end-to-end predictive maintenance pipeline for turbofan engine Remaining Useful Life prediction. By comparing a traditional Random Forest baseline with a deep learning LSTM model, the study highlights the critical importance of temporal modeling in degradation analysis. The LSTM-based approach significantly outperforms the baseline, achieving high accuracy and robustness, making it suitable for real-world aerospace maintenance applications.

